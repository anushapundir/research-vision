# Research Vision

**PDF document analysis and summarization using classical Image Processing, OCR, and AI.**

An academic project for Image and Video Processing course that implements an end-to-end pipeline for research paper analysis.

## ğŸš€ Quick Start

### First-Time Setup

If you cloned or have the old structure, clean up legacy files:
```powershell
.\cleanup.ps1
```

### Installation

```powershell
pip install -r requirements.txt
```

### Run Preprocessing Web App

```powershell
streamlit run app/streamlit_preprocess.py
```

Access the app at `http://localhost:8501`

### Run CLI Demo

```powershell
python scripts/demo.py
```

## ğŸ“‹ Features

### âœ… Implemented (Phase 1: Preprocessing)

- **PDF to Image Conversion** - High-quality rendering at configurable DPI using PyMuPDF
- **Classical Image Processing Pipeline**:
  - Grayscale conversion
  - Histogram equalization (global & CLAHE)
  - Gaussian blur denoising
  - Median blur denoising
  - Otsu's thresholding
  - Adaptive thresholding
- **Interactive Web Interface** - View and compare all preprocessing stages
- **Batch Processing** - All pages processed automatically
- **Export Capabilities** - Download processed images

### ğŸš§ Planned (Future Phases)

- **Layout Segmentation** - Text block and figure detection using morphological operations
- **OCR Integration** - Text extraction with Tesseract/EasyOCR
- **AI Summarization** - Research paper summarization using Google Gemini
- **End-to-End Pipeline** - Complete document analysis workflow

## ğŸ—ï¸ Project Structure

```
research-vision/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_preprocess.py     # Preprocessing web interface (âœ… Working)
â”‚   â””â”€â”€ streamlit_full_app.py       # Full pipeline interface (â³ Placeholder)
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ pdf/
â”‚   â”‚   â””â”€â”€ pdf_loader.py           # PDF to image conversion (âœ… Implemented)
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ preprocess.py           # Image processing filters (âœ… Implemented)
â”‚   â”‚
â”‚   â”œâ”€â”€ segmentation/
â”‚   â”‚   â”œâ”€â”€ segmenter.py            # Layout analysis (â³ Placeholder)
â”‚   â”‚   â””â”€â”€ morphology_utils.py     # Morphological operations (â³ Placeholder)
â”‚   â”‚
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â”œâ”€â”€ ocr_engine.py           # Text extraction (â³ Placeholder)
â”‚   â”‚   â””â”€â”€ postprocess_text.py     # Text cleaning (â³ Placeholder)
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ gemini_client.py        # Gemini API interface (â³ Placeholder)
â”‚   â”‚   â””â”€â”€ summary_pipeline.py     # Summarization pipeline (â³ Placeholder)
â”‚   â”‚
â”‚   â””â”€â”€ pipeline/
â”‚       â””â”€â”€ end_to_end.py           # Full pipeline orchestration (â³ Placeholder)
â”‚
â”œâ”€â”€ data/                           # Input PDFs
â”œâ”€â”€ outputs/                        # Processing results
â”‚   â”œâ”€â”€ pages/                      # Original page images
â”‚   â”œâ”€â”€ preprocessed/               # Filtered images
â”‚   â”œâ”€â”€ segments/                   # Segmented regions
â”‚   â”œâ”€â”€ crops_text/                 # Text block crops
â”‚   â”œâ”€â”€ crops_figures/              # Figure crops
â”‚   â”œâ”€â”€ ocr_text/                   # Extracted text
â”‚   â””â”€â”€ summaries/                  # AI-generated summaries
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ preprocessing_tests.ipynb
â”‚   â”œâ”€â”€ segmentation_debug.ipynb
â”‚   â””â”€â”€ ocr_quality_tests.ipynb
â”‚
â”œâ”€â”€ scripts/                        # Utility scripts
â”‚   â””â”€â”€ demo.py                     # CLI demo script
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md                       # This file
```

## ğŸ”¬ Preprocessing Pipeline (Current Implementation)

```
PDF â†’ Load Pages â†’ Grayscale â†’ Histogram Equalization â†’ Denoising â†’ Binarization â†’ Output
                      â†“              â†“                      â†“           â†“
                  (weighted)    (global & CLAHE)    (Gaussian/Median) (Otsu/Adaptive)
```

### Image Processing Techniques

1. **Grayscale Conversion** - Weighted average: `0.299*R + 0.587*G + 0.114*B`
2. **Histogram Equalization** - Global contrast enhancement
3. **CLAHE** - Contrast Limited Adaptive Histogram Equalization
4. **Gaussian Blur** - Noise reduction with Gaussian kernel
5. **Median Blur** - Salt-and-pepper noise removal
6. **Otsu's Thresholding** - Automatic global binarization
7. **Adaptive Thresholding** - Local binarization for varying illumination

## ğŸ“Š Usage Examples

### Preprocessing a PDF (CLI)

```python
from core.pdf.pdf_loader import load_pdf_to_images
from core.preprocessing.preprocess import run_full_preprocessing

# Load PDF
pages = load_pdf_to_images("paper.pdf", dpi=200)

# Preprocess first page
results = run_full_preprocessing(pages[0])

# Access different outputs
grayscale = results['gray']
binary = results['otsu']
adaptive = results['adaptive']
```

### Using Individual Filters

```python
from core.preprocessing.preprocess import (
    to_grayscale,
    equalize_clahe,
    binarize_otsu
)

gray = to_grayscale(page_image)
enhanced = equalize_clahe(gray, clip_limit=2.0, tile_size=8)
binary = binarize_otsu(enhanced)
```

## ğŸ› ï¸ Tech Stack

### Current
- **Python 3.8+** - Core language
- **OpenCV** - Image processing operations
- **PyMuPDF (fitz)** - High-quality PDF rendering
- **NumPy** - Numerical array operations
- **Streamlit** - Interactive web interface
- **Pillow** - Additional image handling

### Planned
- **Tesseract/EasyOCR** - Optical character recognition
- **Google Gemini API** - AI-powered summarization
- **Matplotlib** - Visualization in notebooks

## ğŸ§ª Development

### Jupyter Notebooks

Use the provided notebooks for experimentation:

```powershell
# Install Jupyter if needed
pip install jupyter

# Launch Jupyter
jupyter notebook notebooks/
```

- **preprocessing_tests.ipynb** - Test different preprocessing parameters
- **segmentation_debug.ipynb** - Develop segmentation algorithms
- **ocr_quality_tests.ipynb** - Compare OCR engines and quality

### Project Status

**Phase 1: Preprocessing** âœ… Complete
- All classical image processing filters implemented
- Web and CLI interfaces working
- Batch processing and export functional

**Phase 2: Segmentation** â³ In Progress
- Morphological operations to be implemented
- Connected component analysis
- Text vs. figure classification

**Phase 3: OCR** â³ Planned
- OCR engine integration
- Text cleaning and postprocessing
- Multi-block text merging

**Phase 4: AI Summarization** â³ Planned
- Gemini API integration
- Prompt engineering for research papers
- Structured summary generation

**Phase 5: Full Pipeline** â³ Planned
- End-to-end orchestration
- Complete web interface
- Batch document processing

## ğŸ“ Notes

- This is an academic project for learning classical image processing techniques
- All preprocessing logic is preserved from the original implementation
- The modular structure allows for easy experimentation and extension
- Placeholder modules have clear documentation and type hints for future implementation

## ğŸ‘¥ Contributing

This is an educational project. When implementing future modules:

1. Follow the existing code style and structure
2. Add comprehensive docstrings with type hints
3. Include usage examples in docstrings
4. Test in the corresponding Jupyter notebook
5. Update this README with implementation details

## ğŸ“„ License

Educational project for Image and Video Processing course.

---

**Version**: 2.0.0  
**Research Vision** - From Document to Insight

**Status**: Phase 1 Complete | Phases 2-5 In Development
