"""
Research Vision - PDF Preprocessing Application
Interactive web app to visualize PDF page preprocessing results.

Usage:
    streamlit run app/streamlit_preprocess.py
"""

import streamlit as st
import cv2
import numpy as np
import os
import sys
from pathlib import Path

# Configuration - Use paths relative to project root
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Updated imports for new structure
from core.pdf.pdf_loader import load_pdf_to_images
from core.preprocessing.preprocess import run_full_preprocessing
from core.layout.layout_analysis import LayoutAnalyzer
DATA_DIR = PROJECT_ROOT / "data"
OUTPUTS_DIR = PROJECT_ROOT / "outputs"
PAGES_DIR = OUTPUTS_DIR / "pages"
PREPROCESSED_DIR = OUTPUTS_DIR / "preprocessed"
LAYOUT_ANALYSIS_DIR = OUTPUTS_DIR / "layout_analysis"

# Model Paths
MODEL_CONFIG_PATH = PROJECT_ROOT / "notebooks/models/config.yaml"
MODEL_WEIGHTS_PATH = PROJECT_ROOT / "notebooks/models/model_final.pth"

# Ensure directories exist
DATA_DIR.mkdir(exist_ok=True)
PAGES_DIR.mkdir(parents=True, exist_ok=True)
PREPROCESSED_DIR.mkdir(parents=True, exist_ok=True)
LAYOUT_ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)

@st.cache_resource
def get_layout_analyzer():
    """
    Initialize and cache the LayoutAnalyzer.
    """
    if not MODEL_CONFIG_PATH.exists() or not MODEL_WEIGHTS_PATH.exists():
        st.error("‚ùå Model files not found! Please check notebooks/models/")
        return None
        
    return LayoutAnalyzer(
        config_path=str(MODEL_CONFIG_PATH),
        model_path=str(MODEL_WEIGHTS_PATH)
    )


def numpy_to_streamlit(image: np.ndarray) -> np.ndarray:
    """
    Convert OpenCV BGR/Grayscale image to RGB for Streamlit display.
    
    Args:
        image (np.ndarray): OpenCV image (BGR or grayscale)
        
    Returns:
        np.ndarray: RGB image for Streamlit
    """
    if len(image.shape) == 2:
        # Grayscale - convert to RGB
        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    elif image.shape[2] == 3:
        # BGR to RGB
        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    return image


def save_preprocessing_outputs(page_idx: int, results: dict) -> None:
    """
    Save preprocessing outputs to the outputs directory structure.
    
    Args:
        page_idx (int): Page index (0-based)
        results (dict): Preprocessing results dictionary
    """
    # Save original page
    page_path = PAGES_DIR / f"page_{page_idx + 1:03d}.png"
    cv2.imwrite(str(page_path), results['original'])
    
    # Save key preprocessed outputs
    for name in ['gray', 'otsu', 'adaptive']:
        if name in results:
            output_path = PREPROCESSED_DIR / f"page_{page_idx + 1:03d}_{name}.png"
            cv2.imwrite(str(output_path), results[name])


def main():
    """
    Main Streamlit application.
    """
    # Page configuration
    st.set_page_config(
        page_title="Research Vision - PDF Preprocessor",
        page_icon="üìÑ",
        layout="wide"
    )
    
    # Title and description
    st.title("üìù Research Vision")
    st.markdown("### PDF Document Preprocessing Pipeline")
    st.markdown(
        "Upload a PDF document and apply classical image processing techniques for enhanced text extraction."
    )
    
    st.divider()
    
    # Sidebar for controls
    with st.sidebar:
        st.header("‚öôÔ∏è Controls")
        
        # File uploader
        uploaded_file = st.file_uploader(
            "Upload PDF File",
            type=["pdf"],
            help="Select a PDF file to process"
        )
        
        if uploaded_file is not None:
            # Save uploaded file temporarily
            pdf_path = DATA_DIR / uploaded_file.name
            with open(pdf_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            st.success(f"‚úì Uploaded: {uploaded_file.name}")
            
            # DPI selector
            dpi = st.slider(
                "Resolution (DPI)",
                min_value=100,
                max_value=300,
                value=200,
                step=50,
                help="Higher DPI = better quality but slower processing"
            )
            
            # Load PDF only if not already loaded or if DPI changed
            should_load = (
                'pages' not in st.session_state or 
                st.session_state.get('current_pdf') != uploaded_file.name or
                st.session_state.get('current_dpi') != dpi
            )
            
            if should_load:
                with st.spinner("Loading PDF pages..."):
                    try:
                        pages = load_pdf_to_images(str(pdf_path), dpi=dpi)
                        st.session_state['pages'] = pages
                        st.session_state['current_pdf'] = uploaded_file.name
                        st.session_state['current_dpi'] = dpi
                        st.session_state['pdf_loaded'] = True
                        # Process all pages immediately
                        st.session_state['all_results'] = {}
                        for idx, page in enumerate(pages):
                            results = run_full_preprocessing(page)
                            st.session_state['all_results'][idx] = results
                            # Save outputs to disk
                            save_preprocessing_outputs(idx, results)
                    except Exception as e:
                        st.error(f"‚ùå Error loading PDF: {str(e)}")
                        st.session_state['pdf_loaded'] = False
                        return
            
            pages = st.session_state.get('pages', [])
            st.success(f"‚úì Loaded and processed {len(pages)} page(s)")
            st.info(f"üìÅ Outputs saved to:\n- `{PAGES_DIR.relative_to(PROJECT_ROOT)}/`\n- `{PREPROCESSED_DIR.relative_to(PROJECT_ROOT)}/`")
            
            # Page selector
            if st.session_state.get('pdf_loaded', False) and len(pages) > 0:
                page_index = st.selectbox(
                    "Select Page to View",
                    options=range(len(pages)),
                    format_func=lambda x: f"Page {x + 1}",
                    help="Choose which page to view"
                )
                st.session_state['page_index'] = page_index
        else:
            st.info("üëÜ Upload a PDF file to get started")
            
        st.divider()
        st.header("üß© Layout Analysis")
        enable_layout_analysis = st.checkbox("Enable Layout Analysis", help="Detect text, tables, figures, etc.")
        
        if enable_layout_analysis and st.session_state.get('pdf_loaded', False):
            if st.button("Run Layout Analysis"):
                analyzer = get_layout_analyzer()
                if analyzer:
                    with st.spinner("Running Layout Analysis on all pages..."):
                        layout_results = {}
                        pages = st.session_state.get('pages', [])
                        pdf_name = st.session_state.get('current_pdf', 'document')
                        pdf_stem = Path(pdf_name).stem
                        
                        # Create output directory for this PDF
                        pdf_layout_dir = LAYOUT_ANALYSIS_DIR / pdf_stem
                        pdf_layout_dir.mkdir(parents=True, exist_ok=True)
                        
                        for idx, page in enumerate(pages):
                            # Convert to RGB for layout analysis if needed, but usually cv2 reads as BGR
                            # LayoutParser expects RGB usually. 
                            # Our load_pdf_to_images returns numpy arrays. 
                            # Let's assume they are BGR (standard opencv).
                            # LayoutAnalyzer handles detection.
                            
                            # Create page directory
                            page_dir = pdf_layout_dir / f"page_{idx + 1:03d}"
                            page_dir.mkdir(parents=True, exist_ok=True)
                            
                            # Run detection
                            layout = analyzer.process_image(page)
                            
                            # Extract elements
                            result = analyzer.extract_elements(
                                page, 
                                layout, 
                                output_dir=page_dir,
                                page_name=f"page_{idx + 1:03d}"
                            )
                            
                            # Save visualization
                            viz_path = page_dir / "visualization.png"
                            cv2.imwrite(str(viz_path), result["visualization"])
                            
                            layout_results[idx] = result
                            
                        st.session_state['layout_results'] = layout_results
                        st.success("‚úì Layout Analysis Complete!")
                        st.info(f"üìÅ Results saved to: `{pdf_layout_dir.relative_to(PROJECT_ROOT)}/`")
    
    # Main content area
    if not uploaded_file:
        st.info("üëà Please upload a PDF file from the sidebar to begin.")
        
        # Show usage instructions
        with st.expander("üìñ How to Use"):
            st.markdown("""
            1. **Upload PDF**: Click "Browse files" in the sidebar
            2. **Auto-Processing**: All pages are automatically preprocessed
            3. **Select Page**: Choose which page to view from the dropdown
            4. **Download**: Export processed images for any page
            5. **Outputs**: All results are automatically saved to the `outputs/` directory
            
            **Preprocessing Pipeline:**
            - Grayscale conversion
            - Histogram equalization (global and CLAHE)
            - Gaussian blur (noise reduction)
            - Median blur (salt-and-pepper noise removal)
            - Otsu's thresholding (automatic binary conversion)
            - Adaptive thresholding (local binary conversion)
            """)
        
        return
    
    # Display the selected page results
    if st.session_state.get('pdf_loaded', False):
        page_index = st.session_state.get('page_index', 0)
        all_results = st.session_state.get('all_results', {})
        
        if page_index in all_results:
            results = all_results[page_index]
            
            st.subheader(f"üìÑ Page {page_index + 1} Results")
            
            # Display results in a grid layout
            st.divider()
            st.subheader("üìä Preprocessing Results")
            
            # Row 1: Original and Grayscale
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Original Image**")
                st.image(numpy_to_streamlit(results['original']), use_column_width=True)
            with col2:
                st.markdown("**Grayscale**")
                st.caption("Converted using weighted average: 0.299R + 0.587G + 0.114B")
                st.image(numpy_to_streamlit(results['gray']), use_column_width=True)
            
            # Row 2: Histogram Equalization
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Histogram Equalized**")
                st.caption("Global contrast enhancement using histogram redistribution")
                st.image(numpy_to_streamlit(results['equalized']), use_column_width=True)
            with col2:
                st.markdown("**CLAHE Enhanced**")
                st.caption("Contrast Limited Adaptive Histogram Equalization")
                st.image(numpy_to_streamlit(results['clahe']), use_column_width=True)
            
            # Row 3: Denoising
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Gaussian Blur**")
                st.caption("Weighted average smoothing for Gaussian noise reduction")
                st.image(numpy_to_streamlit(results['gaussian']), use_column_width=True)
            with col2:
                st.markdown("**Median Blur**")
                st.caption("Non-linear filter excellent for salt-and-pepper noise")
                st.image(numpy_to_streamlit(results['median']), use_column_width=True)
            
            # Row 4: Binarization
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Otsu's Thresholding**")
                st.caption("Automatic global threshold using bimodal histogram")
                st.image(numpy_to_streamlit(results['otsu']), use_column_width=True)
            with col2:
                st.markdown("**Adaptive Thresholding**")
                st.caption("Local thresholding for varying illumination")
                st.image(numpy_to_streamlit(results['adaptive']), use_column_width=True)
            
            # Download section
            st.divider()
            st.subheader("üíæ Download Processed Images")
            
            col1, col2, col3 = st.columns(3)
            
            # Prepare download buttons for key outputs
            with col1:
                _, buffer = cv2.imencode('.png', results['gray'])
                st.download_button(
                    label="‚¨áÔ∏è Download Grayscale",
                    data=buffer.tobytes(),
                    file_name=f"page_{page_index + 1}_grayscale.png",
                    mime="image/png"
                )
            
            with col2:
                _, buffer = cv2.imencode('.png', results['otsu'])
                st.download_button(
                    label="‚¨áÔ∏è Download Otsu Binary",
                    data=buffer.tobytes(),
                    file_name=f"page_{page_index + 1}_otsu.png",
                    mime="image/png"
                )
            
                st.download_button(
                    label="‚¨áÔ∏è Download Adaptive Binary",
                    data=buffer.tobytes(),
                    file_name=f"page_{page_index + 1}_adaptive.png",
                    mime="image/png"
                )
            
            # Layout Analysis Results
            layout_results = st.session_state.get('layout_results', {})
            if page_index in layout_results:
                st.divider()
                st.subheader("üß© Layout Analysis Results")
                
                l_result = layout_results[page_index]
                
                # Visualization
                st.markdown("**Detection Visualization**")
                st.image(numpy_to_streamlit(l_result['visualization']), use_column_width=True)
                
                # Detected Elements
                elements = l_result['elements']
                if elements:
                    st.markdown(f"**Detected {len(elements)} Elements**")
                    
                    # Group by type
                    grouped_elements = {}
                    for el in elements:
                        etype = el['type']
                        if etype not in grouped_elements:
                            grouped_elements[etype] = []
                        grouped_elements[etype].append(el)
                    
                    # Create tabs for each type
                    tabs = st.tabs(list(grouped_elements.keys()))
                    
                    for i, (etype, items) in enumerate(grouped_elements.items()):
                        with tabs[i]:
                            for item in items:
                                with st.expander(f"{etype} #{item['id']} (Confidence: N/A)"):
                                    c1, c2 = st.columns([1, 2])
                                    with c1:
                                        st.image(numpy_to_streamlit(item['crop']), use_column_width=True)
                                    with c2:
                                        if item['text']:
                                            st.markdown("**Extracted Text:**")
                                            st.text_area("OCR Output", item['text'], height=150, key=f"text_{page_index}_{item['id']}")
                                        else:
                                            st.info("No text extracted or not a text region.")


if __name__ == "__main__":
    main()
