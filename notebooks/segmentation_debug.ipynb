{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b832c0aa",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b673ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Import preprocessing modules\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pdf_to_images\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_full_preprocessing\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Import segmentation modules\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Import preprocessing modules\n",
    "from core.pdf.pdf_loader import load_pdf_to_images\n",
    "from core.preprocessing.preprocess import run_full_preprocessing\n",
    "\n",
    "# Import segmentation modules (when implemented)\n",
    "# from core.segmentation.segmenter import segment_page_into_regions\n",
    "# from core.segmentation.morphology_utils import apply_dilation, apply_erosion\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155a9f7",
   "metadata": {},
   "source": [
    "## Load and Preprocess Sample Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample page\n",
    "pdf_path = Path(\"data/attention is all you need.pdf\")\n",
    "\n",
    "if pdf_path.exists():\n",
    "    pages = load_pdf_to_images(str(pdf_path), dpi=200)\n",
    "    sample_page = pages[0]\n",
    "    \n",
    "    # Preprocess\n",
    "    results = run_full_preprocessing(sample_page)\n",
    "    binary = results['otsu']  # Use Otsu binarization as input for segmentation\n",
    "    \n",
    "    print(f\"Loaded page with shape: {sample_page.shape}\")\n",
    "    print(f\"Binary image shape: {binary.shape}\")\n",
    "else:\n",
    "    print(f\"PDF not found at {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712973f7",
   "metadata": {},
   "source": [
    "## Morphological Operations Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement morphological operations testing\n",
    "# Once the morphology_utils module is implemented, test:\n",
    "# - Dilation to connect text components\n",
    "# - Erosion to separate touching regions\n",
    "# - Opening to remove noise\n",
    "# - Closing to fill gaps\n",
    "\n",
    "# Example:\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "# dilated = cv2.dilate(binary, kernel, iterations=2)\n",
    "# \n",
    "# fig, axes = plt.subplots(1, 2)\n",
    "# axes[0].imshow(binary, cmap='gray')\n",
    "# axes[0].set_title('Original Binary')\n",
    "# axes[1].imshow(dilated, cmap='gray')\n",
    "# axes[1].set_title('After Dilation')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b422b09",
   "metadata": {},
   "source": [
    "## Connected Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement connected component analysis\n",
    "# Use cv2.connectedComponentsWithStats to find regions\n",
    "# Analyze and classify each component\n",
    "\n",
    "# Example:\n",
    "# num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)\n",
    "# \n",
    "# print(f\"Found {num_labels - 1} components (excluding background)\")\n",
    "# \n",
    "# # Visualize components\n",
    "# colored_labels = np.zeros((binary.shape[0], binary.shape[1], 3), dtype=np.uint8)\n",
    "# for label in range(1, num_labels):\n",
    "#     colored_labels[labels == label] = np.random.randint(0, 255, 3)\n",
    "# \n",
    "# plt.imshow(colored_labels)\n",
    "# plt.title('Connected Components')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8dcaf",
   "metadata": {},
   "source": [
    "## Text vs. Figure Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ed37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Develop classification heuristics\n",
    "# Features to consider:\n",
    "# - Aspect ratio (width/height)\n",
    "# - Area (in pixels)\n",
    "# - Density (filled pixels / bounding box area)\n",
    "# - Position on page\n",
    "# - Proximity to other components\n",
    "\n",
    "# Example classification logic:\n",
    "# def classify_component(stats):\n",
    "#     x, y, w, h, area = stats\n",
    "#     aspect_ratio = w / h if h > 0 else 0\n",
    "#     \n",
    "#     # Text typically has aspect ratio between 0.1 and 10\n",
    "#     # Figures often have aspect ratio closer to 1\n",
    "#     if 0.1 < aspect_ratio < 10 and area > 100:\n",
    "#         return 'text'\n",
    "#     elif aspect_ratio > 0.5 and area > 5000:\n",
    "#         return 'figure'\n",
    "#     else:\n",
    "#         return 'noise'\n",
    "#     \n",
    "# return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f44d8",
   "metadata": {},
   "source": [
    "## Visualize Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Once segmentation is implemented, visualize results\n",
    "# regions = segment_page_into_regions(binary)\n",
    "# \n",
    "# # Draw bounding boxes on original image\n",
    "# display_img = sample_page.copy()\n",
    "# \n",
    "# for text_block in regions['text_blocks']:\n",
    "#     x, y, w, h = text_block['bbox']\n",
    "#     cv2.rectangle(display_img, (x, y), (x+w, y+h), (0, 255, 0), 2)  # Green for text\n",
    "# \n",
    "# for figure_block in regions['figure_blocks']:\n",
    "#     x, y, w, h = figure_block['bbox']\n",
    "#     cv2.rectangle(display_img, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Blue for figures\n",
    "# \n",
    "# plt.figure(figsize=(12, 16))\n",
    "# plt.imshow(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Segmentation Results: Green=Text, Blue=Figures')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e1d56c",
   "metadata": {},
   "source": [
    "## Extract and Display Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract and display individual text and figure crops\n",
    "# Useful for OCR testing and quality assessment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
